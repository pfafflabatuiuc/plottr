{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from typing import Tuple, Any, Optional, Union, Dict, List\n",
    "from collections import OrderedDict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea and basic use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At its heart an \"Analysis\" is some sort of routine that has data as input, and some number of parameters as output. \n",
    "We'll therefore be able to break down everything in terms of a few different types of basic objects:\n",
    "\n",
    "- `Analysis`: describes the routine we subject the data to.\n",
    "- `AnalysisResult`: the output of the analysis. Will always contain at least output parameters, plus any other information/methods that might be specific to the type of analysis we perform.\n",
    "- `Parameter`: output parameters that contain values plus some metadata.\n",
    "\n",
    "What we'd like is to be able to use the analysis in the following way:\n",
    "\n",
    "```python\n",
    ">>> result = analyze(MyAnalysis, coordinates, data)\n",
    ">>> print(result.parameters['some_output'].value)\n",
    "... 3.14\n",
    "```\n",
    "\n",
    "It should not matter at all what kind of analysis we run -- the access of output can always be uniform. \n",
    "The result of some analysis types might be more complex.\n",
    "For example, a fit result can contain a function that allows accessing the best fit, and its parameters might include uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to have base classes that all types of analysis can use. \n",
    "More complex analysis types will extend the basics ones.\n",
    "For parameters we'll build on the idea of `Parameter` and `Parameters` in `lmfit`.\n",
    "We want out versions largely compatible with the lmfit ones to be able to convert quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter:\n",
    "    \n",
    "    def __init__(self, name, value: Any = None, **kw: Any):\n",
    "        self.name = name\n",
    "        self.value = value\n",
    "        self._attrs = {}\n",
    "        for k, v in kw:\n",
    "            self._attrs[k] = v\n",
    "            \n",
    "    def __getattr__(self, key):\n",
    "        return self._attrs[k]\n",
    "\n",
    "\n",
    "class Parameters(OrderedDict):\n",
    "    \"\"\"A collection of parameters\"\"\"\n",
    "    \n",
    "    def add(self, name: str, **kw: Any):\n",
    "        \"\"\"Add/overwrite a parameter in the collection.\"\"\"\n",
    "        self[name] = Parameter(name, **kw)\n",
    "\n",
    "\n",
    "class AnalysisResult(object):\n",
    "    \n",
    "    def __init__(self, parameters: Dict[str, Union[Dict[str, Any], Any]]):\n",
    "        self.params = Parameters()\n",
    "        for k, v in parameters.items():\n",
    "            if isinstance(v, dict):\n",
    "                self.params.add(k, **v)\n",
    "            else:\n",
    "                self.params.add(k, value=v)\n",
    "                \n",
    "    def eval(self, *args: Any, **kwargs: Any) -> np.ndarray:\n",
    "        \"\"\"Analysis types that produce data (like filters or fits) should implement this.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "\n",
    "class Analysis(object):\n",
    "    \"\"\"Basic analysis object.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinates\n",
    "        may be a single 1d numpy array (for a single coordinate) or a tuple\n",
    "        of 1d arrays (for multiple coordinates).\n",
    "    data\n",
    "        a 1d array of data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, coordinates: Union[Tuple[np.ndarray, ...], np.ndarray], data: np.ndarray):\n",
    "        \"\"\"Constructor of `Analysis`. \"\"\"\n",
    "        self.coordinates = coordinates\n",
    "        self.data = data\n",
    "        \n",
    "    def analyze(self, coordinates, data, *args: Any, **kwargs: Any) -> AnalysisResult:\n",
    "        \"\"\"Needs to be implemented by each inheriting class.\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def run(self, *args: Any, **kwargs: Any) -> AnalysisResult:\n",
    "        return self.analyze(self.coordinates, self.data, **kwargs)\n",
    "    \n",
    "    \n",
    "# def analyze(analysis_class: Analysis, coordinates: Union[Tuple[np.ndarray, ...], np.ndarray], \n",
    "#             data: np.ndarray, **kwarg: Any) -> AnalysisResult:\n",
    "#     analysis = analysis_class(coordinates, data)\n",
    "#     return analysis.run(**kwarg)\n",
    "    \n",
    "    \n",
    "class FindMax(Analysis):\n",
    "    \"\"\"A simple example class to illustrate the concept.\"\"\"\n",
    "    \n",
    "    def analyze(self, xvals, yvals):\n",
    "        i = np.argmax(yvals)\n",
    "        \n",
    "        return AnalysisResult(\n",
    "            dict(\n",
    "                max_val=yvals[i],\n",
    "                max_pos=xvals[i]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01029839 0.3182288  0.45905976 0.17431109 0.32107715 0.78818021\n",
      " 0.95962545 0.04488793 0.25833699 0.45830823]\n",
      "6 0.9596254515651905\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "y = np.random.rand(10)\n",
    "print(y)\n",
    "\n",
    "analysis = FindMax(x, y)\n",
    "result = analysis.run()\n",
    "\n",
    "print(result.params['max_pos'].value, result.params['max_val'].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting is now simply a specific type of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitResult(AnalysisResult):\n",
    "    \n",
    "    def __init__(self, lmfit_result: lmfit.model.ModelResult):\n",
    "        self.lmfit_result = lmfit_result\n",
    "        self.params = lmfit_result.params\n",
    "        \n",
    "    def eval(self, *args: Any, **kwargs: Any):\n",
    "        return self.lmfit_result.eval(*args, **kwargs)\n",
    "\n",
    "\n",
    "class Fit(Analysis):\n",
    "    \n",
    "    @staticmethod\n",
    "    def model(*arg, **kwarg) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "           \n",
    "    def analyze(self, coordinates, data, dry=False, params={}, **fit_kwargs):\n",
    "        model = lmfit.model.Model(self.model)\n",
    "        \n",
    "        _params = lmfit.Parameters()\n",
    "        for pn, pv in self.guess(coordinates, data).items():\n",
    "            _params.add(pn, value=pv)\n",
    "        for pn, pv in params:\n",
    "            _params[pn] = pv\n",
    "        \n",
    "        if dry:\n",
    "            lmfit_result = lmfit.model.ModelResult(model, params=_params, \n",
    "                                                   data=data, coordinates=coordinates)\n",
    "        else:\n",
    "            lmfit_result = model.fit(data, params=_params, \n",
    "                                     coordinates=coordinates, **fit_kwargs)\n",
    "        \n",
    "        return FitResult(lmfit_result)\n",
    "    \n",
    "    @staticmethod\n",
    "    def guess(self, coordinates, data) -> Dict[str, Any]:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        \n",
    "class CosineFit(Fit):\n",
    "    \n",
    "    @staticmethod\n",
    "    def model(coordinates, A, f, phi, of) -> np.ndarray:\n",
    "        \"\"\"$A \\cos(2 \\pi f x + \\phi) + of$\"\"\"\n",
    "        return A * np.cos(2 * np.pi * coordinates * f + phi) + of\n",
    "    \n",
    "    @staticmethod\n",
    "    def guess(coordinates, data):\n",
    "        of = np.mean(data)\n",
    "        A = (np.max(data) - np.min(data)) / 2.\n",
    "        \n",
    "        fft_val = np.fft.rfft(data)[1:]\n",
    "        fft_frq = np.fft.rfftfreq(data.size, np.mean(coordinates[1:]-coordinates[:-1]))[1:]\n",
    "        idx = np.argmax(np.abs(fft_val))\n",
    "        f = fft_frq[idx]\n",
    "        phi = np.angle(fft_val[idx])\n",
    "        \n",
    "        return dict(A=A, of=of, f=f, phi=phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b933acee5e7c422aa0c4ad6f012f9208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Model]]\n",
      "    Model(model)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 26\n",
      "    # data points      = 51\n",
      "    # variables        = 4\n",
      "    chi-square         = 1.99778913\n",
      "    reduced chi-square = 0.04250615\n",
      "    Akaike info crit   = -157.229009\n",
      "    Bayesian info crit = -149.501707\n",
      "[[Variables]]\n",
      "    A:    1.54433140 +/- 0.04099138 (2.65%) (init = 1.751884)\n",
      "    of:   0.53002359 +/- 0.03143838 (5.93%) (init = 0.5102376)\n",
      "    f:    0.99311124 +/- 0.00816438 (0.82%) (init = 0.9803922)\n",
      "    phi: -3.14572689 +/- 0.05812046 (1.85%) (init = -3.063049)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(f, phi)  = -0.889\n",
      "    C(of, f)   =  0.396\n",
      "    C(of, phi) = -0.351\n",
      "    C(A, f)    = -0.142\n",
      "    C(A, phi)  =  0.126\n"
     ]
    }
   ],
   "source": [
    "tvals = np.linspace(0, 2, 51)\n",
    "data = 1.5 * np.cos(2*np.pi*1 * tvals + np.pi) + 0.5 + np.random.normal(scale=0.2, size=tvals.size)\n",
    "\n",
    "fit = CosineFit(tvals, data)\n",
    "fit_guess = fit.run(dry=True)\n",
    "fit_result = fit.run()\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(tvals, data, 'o', label='data')\n",
    "ax.plot(tvals, fit_guess.eval(coordinates=tvals), '--', zorder=-1, label='guess')\n",
    "ax.plot(tvals, fit_result.eval(coordiantes=tvals), '-', label='fit to: ' + fit.model.__doc__, lw=2)\n",
    "ax.legend(loc=0, fontsize='small')\n",
    "\n",
    "print(fit_result.lmfit_result.fit_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
